{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"/Users/paddy/Documents/Github/FretCoach/web/web-backend/.env\")\n",
    "from opik import Opik\n",
    "\n",
    "# Connect to Opik\n",
    "opik_client = Opik()\n",
    "\n",
    "# Get source dataset\n",
    "source_dataset = opik_client.get_dataset(name=\"FretCoach Live AI Feedback\")\n",
    "all_items = source_dataset.get_items()\n",
    "\n",
    "# Transform items to optimizer format\n",
    "def to_optimizer_format(items):\n",
    "    return [\n",
    "        {\n",
    "            \"input\": item['input']['messages'][0][-1]['content'],\n",
    "            \"expected_output\": item['expected_output']['generations'][0][0]['text']\n",
    "        }\n",
    "        for item in items\n",
    "    ]\n",
    "\n",
    "# Split: 35 for train, 9 for validation\n",
    "train_items = to_optimizer_format(all_items[:35])\n",
    "val_items = to_optimizer_format(all_items[35:44])\n",
    "\n",
    "# Create train dataset\n",
    "train_dataset = opik_client.create_dataset(name=\"fretcoach_live_ai_feedback_train_35\")\n",
    "train_dataset.insert(train_items)\n",
    "print(f\"Created train dataset with {len(train_items)} items\")\n",
    "\n",
    "# Create val dataset\n",
    "val_dataset = opik_client.create_dataset(name=\"fretCoach_live_ai_feedback_val_9\")\n",
    "val_dataset.insert(val_items)\n",
    "print(f\"Created validation dataset with {len(val_items)} items\")\n",
    "\n",
    "print(\"\\nSample train item:\")\n",
    "print(train_items[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff4390",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41c0cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = opik_client.get_dataset(name=\"fretcoach_live_ai_feedback_train_25\")\n",
    "validation_dataset = opik_client.get_dataset(name=\"fretcoach_live_ai_feedback_val_9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "v28c5aam5if",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using LLM-as-judge with Perplexity Sonar Pro\n",
    "# Requires: PPLX_API_KEY in your .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5224a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from opik.evaluation.metrics.score_result import ScoreResult\n",
    "\n",
    "# Initialize Perplexity client\n",
    "perplexity_client = OpenAI(\n",
    "    api_key=os.getenv(\"PPLX_API_KEY\"),\n",
    "    base_url=\"https://api.perplexity.ai\"\n",
    ")\n",
    "\n",
    "def llm_judge_metric(\n",
    "    dataset_item: dict[str, Any],\n",
    "    llm_output: str\n",
    ") -> ScoreResult:\n",
    "    \"\"\"\n",
    "    Evaluates coaching feedback quality with emphasis on:\n",
    "    - Not repeating metrics already shown in UI\n",
    "    - Being actionable and specific\n",
    "    - Adding coaching value beyond the numbers\n",
    "    \"\"\"\n",
    "    \n",
    "    judge_prompt = f\"\"\"You are evaluating guitar coaching feedback quality.\n",
    "\n",
    "INPUT METRICS (already shown in UI):\n",
    "{dataset_item['input']}\n",
    "\n",
    "GENERATED FEEDBACK:\n",
    "{llm_output}\n",
    "\n",
    "EXPECTED FEEDBACK EXAMPLE:\n",
    "{dataset_item['expected_output']}\n",
    "\n",
    "Evaluate the GENERATED FEEDBACK on a scale of 0.0 to 1.0 based on:\n",
    "\n",
    "1. **Non-redundancy (40%)**: Does it avoid repeating metric numbers already in the UI? (e.g., don't say \"your pitch is 70%\" - that's already shown)\n",
    "2. **Actionability (30%)**: Does it give specific, actionable advice? (e.g., \"move to 5th position\" vs vague \"improve your playing\")\n",
    "3. **Coaching value (30%)**: Does it interpret what the metrics mean and suggest concrete fixes?\n",
    "\n",
    "CRITICAL: Heavy penalty if feedback just restates numbers from the input.\n",
    "\n",
    "Respond with ONLY a number between 0.0 and 1.0, nothing else.\"\"\"\n",
    "\n",
    "    response = perplexity_client.chat.completions.create(\n",
    "        model=\"sonar-pro\",\n",
    "        messages=[{\"role\": \"user\", \"content\": judge_prompt}],\n",
    "        max_tokens=10,\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    score_text = response.choices[0].message.content.strip()\n",
    "    try:\n",
    "        score = float(score_text)\n",
    "        score = max(0.0, min(1.0, score))  # Clamp to [0, 1]\n",
    "    except ValueError:\n",
    "        score = 0.0  # Default to 0 if parsing fails\n",
    "    \n",
    "    return ScoreResult(\n",
    "        value=score,\n",
    "        name=\"coaching_quality\",\n",
    "        reason=f\"LLM judge score: {score:.3f} (emphasizing non-redundancy and actionability)\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "594b4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opik_optimizer import ChatPrompt\n",
    "\n",
    "# Define the prompt to optimize\n",
    "system_prompt = \"\"\"You are a direct guitar coach giving quick real-time feedback.                                          \n",
    "                                                                                                                                      \n",
    "  Your feedback MUST be 1-2 sentences, maximum 30 words total.                                                                        \n",
    "                                                                                                                                      \n",
    "  Format: \"[What's good], but [what's weak] - [specific actionable fix]\"                                                              \n",
    "                                                                                                                                      \n",
    "  Metric interpretations and specific fixes:                                                                                          \n",
    "  - Pitch Accuracy: How cleanly notes are fretted (low = finger pressure issues)                                                      \n",
    "    → Fix: \"ease finger pressure\" or \"focus on clean fretting\"                                                                        \n",
    "                                                                                                                                      \n",
    "  - Scale Conformity: Playing correct scale notes across fretboard positions (low = stuck in one position or wrong notes)             \n",
    "    → Fix: \"explore positions 5-7\" or \"move up the fretboard\" or \"try higher positions now\"                                           \n",
    "                                                                                                                                      \n",
    "  - Timing Stability: Consistency of note spacing (low = rushing, dragging, uneven rhythm)                                            \n",
    "    → Fix: \"use a metronome\" or \"practice with metronome at 60 BPM\" or \"slow down and count\"                                          \n",
    "                                                                                                                                      \n",
    "  Examples:                                                                                                                           \n",
    "  - \"Timing is solid at 98%, but scale conformity at 73% means you're stuck. Move up to the 5th position now.\"                        \n",
    "  - \"Pitch is excellent and timing good, but scale conformity needs work. Explore different fretboard positions - try 7th and 9th     \n",
    "  frets.\"                                                                                                                             \n",
    "  - \"Great scale coverage, but timing stability is low at 45%. Practice with a metronome to build consistency.\"                       \n",
    "                                                                                                                                      \n",
    "  Be direct, conversational, and vary your wording. Maximum 30 words.\"\"\"\n",
    "\n",
    "# Map into an OpenAI-style chat prompt object\n",
    "prompt = ChatPrompt(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"{input}\"}\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d56c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opik_optimizer import HRPO\n",
    "\n",
    "# Setup optimizer and configuration parameters\n",
    "optimizer = HRPO(\n",
    "  model=\"openai/gpt-4o-mini\",\n",
    "  model_parameters={\"temperature\": 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93c6285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute optimizer\n",
    "optimization_result = optimizer.optimize_prompt(\n",
    "  prompt=prompt, # our ChatPrompt\n",
    "  dataset=dataset, # our Opik dataset\n",
    "  validation_dataset=validation_dataset, # optional, hold-out test\n",
    "  metric=llm_judge_metric, # LLM judge focusing on non-redundancy and actionability\n",
    "  max_trials=10, # optional, number of runs\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FretCoach",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
